{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# autoreload\n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "!git clone https://github.com/shiukaheng/minGS.git\n",
        "#!git clone https://github.com/nadavo11/Aqua-Splat-Aquatic-3D-Novel-View-synthesis-Via-in-scene-deflection.git\n",
        "\n",
        "!pip install plyfile lpips viser requests imageio matplotlib --q\n",
        "\n",
        "# make sure we have a compiler helper\n",
        "!pip install ninja  # speeds up CUDA builds\n",
        "\n",
        "# --- diff-gaussian-rasterization\n",
        "!pip install -e ./minGS/submodules/diff-gaussian-rasterization\n",
        "\n",
        "# --- simple-knn\n",
        "!pip install -e ./minGS/submodules/simple-knn\n",
        "\n",
        " # system packages\n",
        "! sudo apt install ffmpeg colmap\n",
        "\n",
        "! pip install pycolmap\n",
        "\n",
        "# python env (same one you train GS in)\n",
        "! pip install numpy pillow tqdm\n",
        "\n",
        "!sudo apt update && sudo apt install xvfb mesa-utils libgl1-mesa-dri -y\n",
        "\n",
        "!pip install pycolmap\n",
        "\n",
        "!pip install -e ./minGS/submodules/diff-gaussian-rasterization\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/minGS')\n",
        "sys.path.append('/content/minGS/submodules/diff-gaussian-rasterization')\n",
        "sys.path.append('/content/minGS/submodules/simple-knn')\n",
        "sys.path.append('/content/minGS')\n",
        "\n",
        "# aquatic_gs_baseline.py ‚Äì baseline Gaussian Splatting demo (using Tanks&Temples 'Barn' COLMAP dataset)\n",
        "# Automatically install missing dependencies and run Gaussian Splatting demo for 'Barn'.\n",
        "\n",
        "# ------- Dependencies installation (run once at start) ------------------------\n",
        "import importlib\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "# List of PyPI packages and minGS repo to ensure installed\n",
        "REQUIRED_PKGS = [\n",
        "    \"git+https://github.com/shiukaheng/minGS.git\",  # Gaussian Splatting core\n",
        "    \"plyfile\",                                       # COLMAP PLY support\n",
        "    \"lpips\",                                         # perceptual loss\n",
        "    \"viser\",                                         # visualization helper\n",
        "    \"requests\",                                      # HTTP\n",
        "    \"imageio\",                                       # image I/O\n",
        "    \"matplotlib\"                                     # plotting\n",
        "]\n",
        "\n",
        "for pkg in REQUIRED_PKGS:\n",
        "    name = pkg.split(\"#\")[0].strip()\n",
        "    try:\n",
        "        if name.startswith(\"git+\"):\n",
        "            importlib.import_module(\"gs\")\n",
        "        else:\n",
        "            importlib.import_module(name)\n",
        "    except ImportError:\n",
        "        print(f\"Installing {pkg}...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9AKBR67tO5z",
        "outputId": "6720a6ad-5428-456f-dc04-403efa5ce48e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'minGS' already exists and is not an empty directory.\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (1.11.1.4)\n",
            "Obtaining file:///content/minGS/submodules/diff-gaussian-rasterization\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Installing collected packages: diff_gaussian_rasterization\n",
            "  Attempting uninstall: diff_gaussian_rasterization\n",
            "    Found existing installation: diff_gaussian_rasterization 0.0.0\n",
            "    Uninstalling diff_gaussian_rasterization-0.0.0:\n",
            "      Successfully uninstalled diff_gaussian_rasterization-0.0.0\n",
            "  Running setup.py develop for diff_gaussian_rasterization\n",
            "Successfully installed diff_gaussian_rasterization-0.0.0\n",
            "Obtaining file:///content/minGS/submodules/simple-knn\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Installing collected packages: simple_knn\n",
            "  Attempting uninstall: simple_knn\n",
            "    Found existing installation: simple_knn 0.0.0\n",
            "    Uninstalling simple_knn-0.0.0:\n",
            "      Successfully uninstalled simple_knn-0.0.0\n",
            "  Running setup.py develop for simple_knn\n",
            "Successfully installed simple_knn-0.0.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "colmap is already the newest version (3.7-2).\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n",
            "Requirement already satisfied: pycolmap in /usr/local/lib/python3.11/dist-packages (3.11.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pycolmap) (2.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 384 kB in 3s (131 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "37 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "mesa-utils is already the newest version (8.4.0-1ubuntu1).\n",
            "libgl1-mesa-dri is already the newest version (23.2.1-1ubuntu3.1~22.04.3).\n",
            "xvfb is already the newest version (2:21.1.4-2ubuntu1.7~22.04.14).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n",
            "Requirement already satisfied: pycolmap in /usr/local/lib/python3.11/dist-packages (3.11.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pycolmap) (2.0.2)\n",
            "Obtaining file:///content/minGS/submodules/diff-gaussian-rasterization\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Installing collected packages: diff_gaussian_rasterization\n",
            "  Attempting uninstall: diff_gaussian_rasterization\n",
            "    Found existing installation: diff_gaussian_rasterization 0.0.0\n",
            "    Uninstalling diff_gaussian_rasterization-0.0.0:\n",
            "      Successfully uninstalled diff_gaussian_rasterization-0.0.0\n",
            "  Running setup.py develop for diff_gaussian_rasterization\n",
            "Successfully installed diff_gaussian_rasterization-0.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Baseline script to train **minGS** on a small COLMAP dataset.\n",
        "- installs the minimal 3‚ÄëD Gaussian Splatting implementation\n",
        "- downloads a tiny demo dataset (bonsai) if `DATA_DIR` is empty\n",
        "- runs a very short training loop (2‚ÄØk iters)\n",
        "- dumps preview renderings every 100 steps\n",
        "- saves the final model to `aquatic_baseline_gs.pth`\n",
        "\n",
        "You can use the same scaffolding later and simply swap the `GaussianModel.forward` call with your deflection‚Äëaware version.\n"
      ],
      "metadata": {
        "id": "23RU14tUD8mr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# data"
      ],
      "metadata": {
        "id": "fwX3XWotKVoH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import snapshot_download\n",
        "\n",
        "local_path = snapshot_download(\n",
        "    repo_id=\"nadavo11/red_truck_GS\",\n",
        "    repo_type=\"dataset\",\n",
        "    local_dir=\"/content/red_truck_GS\",    # any path you like\n",
        "    resume_download=True                      # skip files already on disk\n",
        ")\n",
        "print(\"Dataset at:\", local_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289,
          "referenced_widgets": [
            "7bed86e6c3fe45888dc7b8a82815e812",
            "1bbfcac999744d2bbcdb9ae3bff4252a",
            "2e4e999d8e6841a09a506f92a5d6a29d",
            "2e6565837a2b407f9ddd08a19bd326a9",
            "dbdb641761d245eeb3a485a6dbdd2fa1",
            "7482aba2869745ebb42461c7ac331ac0",
            "e3380acf90a2413181a4a3491a34f055",
            "ae0ef667a0d14f6ca759d38b16a50613",
            "5e28997afeaf4e87bc16586577e11efd",
            "7e830334d7514768bdcdd0f3ae1ed412",
            "c56ce44cfa304975a33c0a8b92c2a3d3",
            "0b3de518d7c041ac897b3fb8b3d31550",
            "f585bea34dc646a29bb34729ba537519",
            "6c59ca379eb0438eb1353cff920ebb56",
            "ca91fed513184892bc0e4f38ae497fde",
            "9d34e8e50bec42e09175c70942a9e042",
            "d0ba2780b38449ada7ecb92d151e4619",
            "38d00262ef4a4461801f08558a4f18c4",
            "0722f9426da3494f9f00ffda40b3278b",
            "e03f56ecab874ec0882e9cd4cb4cbcca",
            "b45418768dd546549681b9a1e0432e77",
            "02818d284bef4c0ab083b71262548e17",
            "152dcf7d57dc4924a21d6e9eb59877ba",
            "36222de2f2de4c738e8992dee986f4ff",
            "70529781b06b49b98543acf2333db639",
            "7e012eaf5d104b11a6fa8dbcc8996024",
            "9891454ad27948459678e44fb53e0b13",
            "d7ac9a657bf44549bd4dac732ce69a98",
            "26a7104136474deeb803df9a8631424e",
            "2cef093ddb104cf89dfed1df99e03dd5",
            "e8716887610d46e481f928149a7da2eb",
            "a8b1a1588378440d84411e6ca2245be0",
            "7ab5d174b3d046e2ae87d812f9aeab0b"
          ]
        },
        "id": "B0wh_WQolK-_",
        "outputId": "1232b6f7-b4de-4387-cd34-74819176b73b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 1334 files:   0%|          | 0/1334 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7bed86e6c3fe45888dc7b8a82815e812"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "val.txt:   0%|          | 0.00/511 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b3de518d7c041ac897b3fb8b3d31550"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train.txt:   0%|          | 0.00/4.69k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "152dcf7d57dc4924a21d6e9eb59877ba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset at: /content/red_truck_GS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## split train and test"
      ],
      "metadata": {
        "id": "9YjOy2ecDl1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from pathlib import Path\n",
        "from gs.io.colmap import load\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 1. load every COLMAP view\n",
        "# ------------------------------------------------------------------\n",
        "DATA_DIR = Path(\"red_truck_GS\")\n",
        "cameras, pointcloud = load(str(DATA_DIR))\n",
        "\n",
        "all_cams = list(cameras)          # list[BaseCamera]\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 2. SPLIT  ‚Äî 90 % train / 10 % val  (or whatever ratio you like)\n",
        "# ------------------------------------------------------------------\n",
        "random.seed(42)                             # reproducible split\n",
        "random.shuffle(all_cams)\n",
        "\n",
        "val_frac   = 0.10                           # ‚Üê tweak here\n",
        "n_val      = max(1, int(len(all_cams)*val_frac))\n",
        "val_cams   = all_cams[:n_val]\n",
        "train_cams = all_cams[n_val:]\n",
        "\n",
        "print(f\"{len(train_cams)} train views   |   {len(val_cams)} val views\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvqX37tbDlo-",
        "outputId": "ca02933a-9c4a-4498-f6c6-93b0c8aebff6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "67 train views   |   7 val views\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split_red_truck.py\n",
        "from pathlib import Path\n",
        "import random, json\n",
        "\n",
        "root      = Path(\"red_truck_GS\")\n",
        "img_dir   = root / \"images\"          # where COLMAP put the JPG/PNG frames\n",
        "split_dir = root / \"splits\"          # just text files with the frame ids\n",
        "split_dir.mkdir(exist_ok=True)\n",
        "\n",
        "all_imgs  = sorted(img_dir.glob(\"*\"))      # 000001.png, 000002.png ‚Ä¶\n",
        "random.seed(42)\n",
        "random.shuffle(all_imgs)\n",
        "\n",
        "val_frac = 0.1\n",
        "n_val    = max(1, int(len(all_imgs)*val_frac))\n",
        "val_imgs, train_imgs = all_imgs[:n_val], all_imgs[n_val:]\n",
        "\n",
        "# write text files (handy for other scripts)\n",
        "(split_dir / \"train.txt\").write_text(\"\\n\".join(p.name for p in train_imgs))\n",
        "(split_dir / \"val.txt\").write_text(\"\\n\".join(p.name for p in val_imgs))\n",
        "\n",
        "print(f\"train {len(train_imgs)}  |  val {len(val_imgs)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hB2oWRWnDkvK",
        "outputId": "26ddb2e8-3ebb-49f3-de55-c350e23ada24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train 293  |  val 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# link_views.py\n",
        "from pathlib import Path, os\n",
        "\n",
        "root = Path(\"red_truck_GS\")\n",
        "for split in (\"train\", \"val\"):\n",
        "    (root / split / \"images\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "for split in (\"train\", \"val\"):\n",
        "    for name in (root / \"splits\" / f\"{split}.txt\").read_text().splitlines():\n",
        "        src = root / \"images\" / name\n",
        "        dst = root / split / \"images\" / name\n",
        "        if not dst.exists():\n",
        "            os.link(src, dst)      # hard-link ‚Üí 0-byte overhead\n"
      ],
      "metadata": {
        "id": "TrklJw_SmviW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Mrxsug3TlKsg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ------- Imports --------------------------------------------------------------\n",
        "import os,tempfile, zipfile, requests, imageio, torch\n",
        "from pathlib import Path\n",
        "from plyfile import PlyElement\n",
        "\n",
        "from gs.core.GaussianModel import GaussianModel\n",
        "from gs.io.colmap import load\n",
        "from gs.helpers.loss import l1_loss\n",
        "\n",
        "url = \"https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/datasets/input/tandt_db.zip\"\n",
        "ROOT = Path(\"./data\")\n",
        "DATA_NAME = \"tandt\"\n",
        "DATA_DIR = Path(f\"./data/{DATA_NAME}/train\")\n",
        "# ------- Prepare dataset ------------------------------------------------------\n",
        "# We'll download the authors' Tanks&Temples+DeepBlending COLMAP archive and extract only the 'tandt' scene\n",
        "from baseline_utils.utils import *\n",
        "get_data_from_web(url, ROOT, DATA_NAME)\n",
        "\n",
        "\n",
        "# ------- Load COLMAP data -----------------------------------------------------\n",
        "# Expects: BARN_DIR/sparse/0/{cameras.bin, images.bin, points3D.bin}, BARN_DIR/images/*\n",
        "cameras, pointcloud = load(str(DATA_DIR))\n",
        "print(f\"Loaded {len(cameras)} cameras and {len(pointcloud.points)} sparse points from Barn\")\n",
        "\n",
        "\n",
        "# ------- Build Gaussian Splatting model ---------------------------------------\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = GaussianModel.from_point_cloud(pointcloud).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, eps=1e-15)\n",
        "\n",
        "# ------- Quick training loop --------------------------------------------------\n",
        "NUM_ITERS = 20000  # keep small for baseline; bump for quality\n",
        "LOG_EVERY = 1000\n",
        "\n",
        "for it in range(NUM_ITERS):\n",
        "    cam = cameras[it % len(cameras)].to(device)\n",
        "    rgb_pred = model(cam)\n",
        "    loss = l1_loss(rgb_pred, cam.image.to(device))\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "    if (it + 1) % LOG_EVERY == 0 or it == 0:\n",
        "        print(f\"iter {it+1:4d}/{NUM_ITERS} | L1 = {loss.item():.4f}\")\n",
        "        vis = (rgb_pred.clamp(0, 1).permute(1, 2, 0).detach().cpu().numpy() * 255).astype('uint8')\n",
        "        torch.save(model.state_dict(), \"aquatic_baseline_gs.pth\")\n",
        "\n",
        "\n",
        "        imageio.imwrite(f\"preview_{it+1:04d}.png\", vis)\n",
        "\n",
        "# ------- Save model -----------------------------------------------------------\n",
        "torch.save(model.state_dict(), \"aquatic_baseline_gs.pth\")\n",
        "print(\"Training finished ‚Äì previews and checkpoint written.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "oltxL53IDigF",
        "outputId": "fd819b03-6c1a-4328-a01f-06d2ba76bdec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'baseline_utils'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-9b0173a971b2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# ------- Prepare dataset ------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# We'll download the authors' Tanks&Temples+DeepBlending COLMAP archive and extract only the 'tandt' scene\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbaseline_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mget_data_from_web\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mROOT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATA_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'baseline_utils'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#nice visuals"
      ],
      "metadata": {
        "id": "7MWUQgd6FtnI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from gs.core.BaseCamera import BaseCamera\n",
        "\n",
        "# --- add a drop-in replacement ------------------------------------------------\n",
        "def _look_at(\n",
        "        eye: torch.Tensor,          # (3,)  camera position\n",
        "        center: torch.Tensor,       # (3,)  look-at point\n",
        "        up: torch.Tensor,           # (3,)  world-up\n",
        "        width: int, height: int,    # image size (px)\n",
        "        fx: float                   # focal length in px (assume square pixels)\n",
        "):\n",
        "    eye_np, center_np, up_np = map(lambda v: v.detach().cpu().numpy(), (eye, center, up))\n",
        "\n",
        "    # Build rotation (camera ‚Üí world) with the usual OpenGL look-at convention\n",
        "    f = center_np - eye_np\n",
        "    f /= np.linalg.norm(f)\n",
        "    s = np.cross(f, up_np)\n",
        "    s /= np.linalg.norm(s)\n",
        "    u = np.cross(s, f)\n",
        "\n",
        "    # Camera‚Äêto-world (R^T | eye); we need world-to-camera, so take the transpose.\n",
        "    R_c2w = np.stack([s, u, -f], axis=0)          # shape (3, 3)\n",
        "    R = R_c2w.T                                   # world ‚Üí camera\n",
        "    t = -R @ eye_np                               # translation in camera frame\n",
        "\n",
        "    fov_x = 2 * np.arctan(width  / (2 * fx))\n",
        "    fov_y = 2 * np.arctan(height / (2 * fx))\n",
        "\n",
        "    return BaseCamera(\n",
        "        image_height=height,\n",
        "        image_width=width,\n",
        "        fov_x=float(fov_x),\n",
        "        fov_y=float(fov_y),\n",
        "        R=R.astype(np.float32),\n",
        "        t=t.astype(np.float32),\n",
        "    )\n",
        "\n",
        "# attach it so the rest of the code can stay identical\n",
        "BaseCamera.look_at = staticmethod(_look_at)\n",
        "# ------------------------------------------------------------------------------\n",
        "\n"
      ],
      "metadata": {
        "id": "lOmQAFlh6FTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from gs.core.BaseCamera import BaseCamera\n",
        "\n",
        "def orbit_around_camera(\n",
        "        ref_cam: BaseCamera,\n",
        "        radius: float,\n",
        "        n_views: int = 120,\n",
        "        axis: str = \"yaw\",            # \"yaw\"  (spin left/right)\n",
        "                                        # \"pitch\" (tilt up/down)\n",
        "                                        # \"roll\"  (spin around optical axis)\n",
        "        up_hint: torch.Tensor | None = None,   # world-space up  (optional)\n",
        "        width: int = 800,\n",
        "        height: int = 800,\n",
        "        fx: float = 700,\n",
        ") -> list[BaseCamera]:\n",
        "\n",
        "    # -- extract the reference-camera transforms -----------------------------\n",
        "    R_wc = ref_cam.world_view_transform[:3, :3].T      # world‚Üêcamera\n",
        "    t_wc = ref_cam.camera_center                       # camera position (world)\n",
        "\n",
        "    # local basis: x = right, y = up, z = -view\n",
        "    axis_vectors = {\n",
        "        \"yaw\":   torch.tensor([0, 1, 0]).to(device),   # rotate around local Y-up\n",
        "        \"pitch\": torch.tensor([1, 0, 0]).to(device),   # rotate around local X-right\n",
        "        \"roll\":  torch.tensor([0, 0, 1]).to(device),   # rotate around local Z-view\n",
        "    }\n",
        "    a_local = axis_vectors[axis].float()\n",
        "\n",
        "    # up vector for look_at; fall back to camera‚Äôs own +Y if none supplied\n",
        "    up_world = up_hint if up_hint is not None else R_wc @ torch.tensor([0, 1, 0],dtype=torch.float).to(device)\n",
        "\n",
        "    cams = []\n",
        "    for theta in torch.linspace(1.2*np.pi, 1.8*np.pi, n_views):\n",
        "        # rotation matrix in *camera* space, then send to world space\n",
        "        cos_t, sin_t = torch.cos(theta), torch.sin(theta)\n",
        "        if axis == \"yaw\":\n",
        "            R_delta = torch.tensor([[ cos_t, 0, sin_t],\n",
        "                                    [     0, 1,     0],\n",
        "                                    [-sin_t, 0, cos_t]]).to(device)\n",
        "        elif axis == \"pitch\":\n",
        "            R_delta = torch.tensor([[1,     0,      0],\n",
        "                                    [0, cos_t, -sin_t],\n",
        "                                    [0, sin_t,  cos_t]]).to(device)\n",
        "        else:  # roll\n",
        "            R_delta = torch.tensor([[cos_t, -sin_t, 0],\n",
        "                                    [sin_t,  cos_t, 0],\n",
        "                                    [    0,      0, 1]]).to(device)\n",
        "\n",
        "        # eye position: start at (radius,0,0) in ref-cam space, rotate, go world\n",
        "        eye_local  = torch.tensor([radius, 0, 0]).to(device)\n",
        "        eye_world  = (R_wc @ (R_delta @ eye_local)) + t_wc\n",
        "\n",
        "        # look-at point = pivot itself (camera centre)\n",
        "        cams.append(\n",
        "            BaseCamera.look_at(\n",
        "                eye_world, t_wc, up_world,\n",
        "                width=width, height=height, fx=fx\n",
        "            ).to(\"cuda\")\n",
        "        )\n",
        "\n",
        "    return cams\n"
      ],
      "metadata": {
        "id": "nas5mrzVK07B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# get the video"
      ],
      "metadata": {
        "id": "3B9wx9EmOsuJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# choose any dataset camera you like (e.g. index 0)\n",
        "ref_cam = cameras[2]\n",
        "device =\"cuda\"\n",
        "# build an orbit that yaws 360¬∞ around that camera\n",
        "cams = orbit_around_camera(\n",
        "    ref_cam,\n",
        "    radius=2.0,      # metres in *camera* space\n",
        "    n_views=120,\n",
        "    axis=\"yaw\",       # try \"pitch\" or \"roll\" for other motions\n",
        "    width=800, height=800, fx=700\n",
        ")\n",
        "\n",
        "# render exactly as before\n",
        "frames = []\n",
        "for cam in cams:\n",
        "    with torch.no_grad():\n",
        "        img = model(cam).clamp(0,1).permute(1,2,0).cpu().numpy()\n",
        "    frames.append((img*255).astype(\"uint8\"))\n",
        "\n",
        "imageio.mimsave(\"pivot_turntable.mp4\", frames, fps=24)\n",
        "print(\"Saved pivot_turntable.mp4\")\n"
      ],
      "metadata": {
        "id": "7bwUk89zK4Hw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "____________"
      ],
      "metadata": {
        "id": "2s-SbADRFz8a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# make our own aquatic data!"
      ],
      "metadata": {
        "id": "mvLHDyexR1NM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from baseline_utils.make_dataset import *"
      ],
      "metadata": {
        "id": "ABOF0Cz3R05q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!colmap feature_extractor --help | grep gpu\n"
      ],
      "metadata": {
        "id": "LZVitRYkCgDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!xvfb-run colmap gui\n"
      ],
      "metadata": {
        "id": "1ULnyo4DEQGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! python /content/Aqua-Splat-Aquatic-3D-Novel-View-synthesis-Via-in-scene-deflection/baseline_utils/make_dataset.py /content/Aqua-Splat-Aquatic-3D-Novel-View-synthesis-Via-in-scene-deflection//baseline_utils/vid.MOV --k 120 --fps 12 --overlap 5 --dataset red_truck_GS/train/ --from_frames\n"
      ],
      "metadata": {
        "id": "KauodXXySTyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## push to hf"
      ],
      "metadata": {
        "id": "dOTaJ0fO7tdQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade huggingface_hub\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "plfysoNW7v9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import HfApi\n",
        "from huggingface_hub import upload_folder\n",
        "api = HfApi()\n",
        "\n",
        "\n",
        "upload_folder(\n",
        "    repo_id=\"nadavo11/red_truck_GS\",\n",
        "    folder_path=\"red_truck_GS\",         # the root we generated\n",
        "    repo_type=\"dataset\",                    # same as above\n",
        "    path_in_repo=\"\",                        # keep structure as-is\n",
        "\n",
        "    ignore_patterns=[\"*.db\"]                # skip the COLMAP DB if you like\n",
        ")"
      ],
      "metadata": {
        "id": "N_iUmKtT71Is"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# train"
      ],
      "metadata": {
        "id": "8g3hJ1R674nd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -X GET \\\n",
        "     \"https://datasets-server.huggingface.co/rows?dataset=nadavo11%2Faquarium-gaussian-splats&config=default&split=train&offset=0&length=100\""
      ],
      "metadata": {
        "id": "qnm2BV7xjL43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------- Imports --------------------------------------------------------------\n",
        "import os,tempfile, zipfile, requests, imageio, torch\n",
        "from pathlib import Path\n",
        "from plyfile import PlyElement\n",
        "\n",
        "from gs.core.GaussianModel import GaussianModel\n",
        "from gs.io.colmap import load\n",
        "from gs.helpers.loss import l1_loss\n",
        "\n",
        "\n",
        "ROOT = Path(\"/content/\")\n",
        "DATA_NAME = \"aquarium\"\n",
        "DATA_DIR = Path(f\"{DATA_NAME}\")\n",
        "# ------- Load COLMAP data -----------------------------------------------------\n",
        "# Expects: BARN_DIR/sparse/0/{cameras.bin, images.bin, points3D.bin}, BARN_DIR/images/*\n",
        "cameras, pointcloud = load(str(DATA_DIR))\n",
        "print(f\"Loaded {len(cameras)} cameras and {len(pointcloud.points)} sparse points from Barn\")\n",
        "\n",
        "\n",
        "# ------- Build Gaussian Splatting model ---------------------------------------\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = GaussianModel.from_point_cloud(pointcloud).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, eps=1e-15)\n",
        "\n",
        "#save as .ply\n",
        "model.save_ply(\"./aquarium_gaussians.ply\",)         # ‚Üê one-liner\n",
        "\n",
        "# ------- Quick training loop --------------------------------------------------\n",
        "NUM_ITERS = 20000  # keep small for baseline; bump for quality\n",
        "LOG_EVERY = 1000\n",
        "\n",
        "for it in range(NUM_ITERS):\n",
        "    cam = cameras[it % len(cameras)].to(device)\n",
        "    rgb_pred = model(cam)\n",
        "    loss = l1_loss(rgb_pred, cam.image.to(device))\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "    if (it + 1) % LOG_EVERY == 0 or it == 0:\n",
        "        print(f\"iter {it+1:4d}/{NUM_ITERS} | L1 = {loss.item():.4f}\")\n",
        "        vis = (rgb_pred.clamp(0, 1).permute(1, 2, 0).detach().cpu().numpy() * 255).astype('uint8')\n",
        "        torch.save(model.state_dict(), \"aquatic_baseline_gs.pth\")\n",
        "        model.save_ply(\"./aquarium_gaussians.ply\")         # ‚Üê one-liner\n",
        "\n",
        "\n",
        "\n",
        "        imageio.imwrite(f\"preview_{it+1:04d}.png\", vis)\n",
        "\n",
        "# ------- Save model -----------------------------------------------------------\n",
        "torch.save(model.state_dict(), \"aquatic_baseline_gs.pth\")\n",
        "print(\"Training finished ‚Äì previews and checkpoint written.\")\n"
      ],
      "metadata": {
        "id": "E7k5qGEDjk1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os,tempfile, zipfile, requests, imageio, torch\n",
        "from pathlib import Path\n",
        "from plyfile import PlyElement\n",
        "\n",
        "from gs.core.GaussianModel import GaussianModel\n",
        "from gs.io.colmap import load\n",
        "from gs.helpers.loss import l1_loss\n",
        "\n",
        "\n",
        "ROOT = Path(\"/content/\")\n",
        "DATA_NAME = \"aquarium\"\n",
        "DATA_DIR = Path(f\"{DATA_NAME}\")\n",
        "# ------- Load COLMAP data -----------------------------------------------------\n",
        "# Expects: BARN_DIR/sparse/0/{cameras.bin, images.bin, points3D.bin}, BARN_DIR/images/*\n",
        "cameras, pointcloud = load(str(DATA_DIR))"
      ],
      "metadata": {
        "id": "PSl0NI0tI3tp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# push to hf"
      ],
      "metadata": {
        "id": "1OrrA3lvL11S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade huggingface_hub\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "bNcSmC-UL3Kl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import upload_folder\n",
        "\n",
        "upload_folder(\n",
        "    repo_id=\"nadavo11/aquarium\",\n",
        "    folder_path=\"aquarium\",         # the root we generated\n",
        "    repo_type=\"dataset\",                    # same as above\n",
        "    path_in_repo=\"\",                        # keep structure as-is\n",
        "    ignore_patterns=[\"*.db\"]                # skip the COLMAP DB if you like\n",
        ")\n",
        "\n",
        "# # add the checkpoints too\n",
        "# upload_folder(\n",
        "#     repo_id=\"nadavo11/aquarium\",\n",
        "#     folder_path=\".\",                        # current dir\n",
        "#     repo_type=\"dataset\",\n",
        "#     path_in_repo=\"checkpoints\",\n",
        "#     #include_patterns=[\"*.pth\", \"*.ply\"]\n",
        "# )\n"
      ],
      "metadata": {
        "id": "2nV05JueL1rc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# retrieve from hf"
      ],
      "metadata": {
        "id": "_5mIl8U5WDuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get dataset from hugging face\n",
        "from huggingface_hub import snapshot_download\n",
        "\n",
        "local_path = snapshot_download(\n",
        "    repo_id=\"nadavo11/aquarium\",\n",
        "    repo_type=\"dataset\",\n",
        "    local_dir=\"aquarium_downloaded\",  # local target folder\n",
        "    local_dir_use_symlinks=False      # ensure real files are copied\n",
        ")\n",
        "\n",
        "print(f\"Dataset downloaded to: {local_path}\")"
      ],
      "metadata": {
        "id": "X9kcpKLRWGcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline Train"
      ],
      "metadata": {
        "id": "5WYPbY1Wkpzw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gs.trainers.basic import *"
      ],
      "metadata": {
        "id": "9E4VuMdKkscx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------- Imports --------------------------------------------------------------\n",
        "import os,tempfile, zipfile, requests, imageio, torch\n",
        "from pathlib import Path\n",
        "from plyfile import PlyElement\n",
        "\n",
        "from gs.core.GaussianModel import GaussianModel\n",
        "from gs.io.colmap import load\n",
        "from gs.helpers.loss import l1_loss\n",
        "\n",
        "\n",
        "ROOT = Path(\"/content/\")\n",
        "DATA_NAME = \"red_truck_GS\"\n",
        "DATA_DIR = \"red_truck_GS\"\n",
        "# ------- Load COLMAP data -----------------------------------------------------\n",
        "# Expects: BARN_DIR/sparse/0/{cameras.bin, images.bin, points3D.bin}, BARN_DIR/images/*\n",
        "cameras, pointcloud = load(str(DATA_DIR))\n",
        "print(f\"Loaded {len(cameras)} cameras and {len(pointcloud.points)} sparse points from Barn\")\n",
        "model = GaussianModel.from_point_cloud(pointcloud)"
      ],
      "metadata": {
        "id": "iZaGCqrFkpgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#public = ngrok.connect(8088, proto=\"http\")   # forwards 8080 ‚Üí HTTPS URL\n",
        "from gs.trainers.basic import *\n",
        "\n",
        "train(model = model,\n",
        "      cameras = train_cams,\n",
        "      iterations = 10000,\n",
        "      densify_until_iter = 10\n",
        "      )"
      ],
      "metadata": {
        "id": "b_0OrS5fmJd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_ply(\"./latest_model.ply\")\n"
      ],
      "metadata": {
        "id": "S3sdNqirMySN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "from gs.core.GaussianModel import GaussianModel\n",
        "from gs.visualization.Viewer import Viewer    # üëà\n",
        "#from pyngrok import ngrok\n",
        "#from pyngrok import ngrok\n",
        "\n",
        "\n",
        "viewer = Viewer(model, frame_rate=15, width=1280,)\n",
        "\n",
        "viewer.render_loop()"
      ],
      "metadata": {
        "id": "3UhfV4nDpcoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install -q pyngrok\n",
        "!ngrok config add-authtoken 2wVlctr7rHbnaxqVEokp84Jwsbh_4nFBXYEQQ8exfAYNPfL8Q\n"
      ],
      "metadata": {
        "id": "h2pVHHHpqD_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.cpu(), \"aquarium.pt\")   # one line\n"
      ],
      "metadata": {
        "id": "Be-mSQJuDZhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "model2 = torch.load(\"aquarium.pt\", weights_only=False)\n",
        "model2.eval()"
      ],
      "metadata": {
        "id": "00a_rS5HJ0Q-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save to ply\n",
        "model2.save_ply(\"./aquarium.ply\")"
      ],
      "metadata": {
        "id": "1gaXi2QMvKEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(\"aquarium.pt\")    # or \"aquatic_baseline_gs.pth\"\n"
      ],
      "metadata": {
        "id": "QmPJRfAVcGzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *baseline*\n"
      ],
      "metadata": {
        "id": "qFITESLqq8Ju"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## data"
      ],
      "metadata": {
        "id": "f5dBkeIe3piZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iO1PVZ7Z3mOv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# get dataset from hugging face\n",
        "from huggingface_hub import snapshot_download\n",
        "\n",
        "local_path = snapshot_download(\n",
        "    repo_id=\"nadavo11/red_truck_GS\",\n",
        "    repo_type=\"dataset\",\n",
        "    local_dir=\"aquarium_downloaded\",  # local target folder\n",
        "    local_dir_use_symlinks=False      # ensure real files are copied\n",
        ")\n",
        "\n",
        "print(f\"Dataset downloaded to: {local_path}\")"
      ],
      "metadata": {
        "id": "FZhjmkwkq7yv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## load train set"
      ],
      "metadata": {
        "id": "lZ-DmTue1gvR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from gs.io.colmap import load\n",
        "\n",
        "root = Path(\"red_truck_GS\")            # repo you cloned from HF\n",
        "\n",
        "# 1. load every view\n",
        "all_cams, pointcloud = load(str(root))       # key = image_id, value = BaseCamera\n",
        "\n",
        "# 2. read the split lists\n",
        "train_ids = set((root/\"splits/train.txt\").read_text().splitlines())\n",
        "val_ids   = set((root/\"splits/val.txt\").read_text().splitlines())\n",
        "\n",
        "\n",
        "train_cams = [cam for cam in all_cams if cam.image_path.split('/')[-1] in train_ids]\n",
        "val_cams   = [cam for cam in all_cams if cam.image_path.split('/')[-1] in val_ids]\n",
        "\n",
        "print(f\"{len(train_cams)} train cams | {len(val_cams)} val cams\")"
      ],
      "metadata": {
        "id": "djjDRZ68umjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## train"
      ],
      "metadata": {
        "id": "ULpTKF9a4K4x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "OoV4Y2qJ3yhj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = GaussianModel.from_point_cloud(pointcloud)\n",
        "#public = ngrok.connect(8088, proto=\"http\")   # forwards 8080 ‚Üí HTTPS URL\n",
        "from gs.trainers.basic import *\n",
        "\n",
        "model = GaussianModel.from_point_cloud(pointcloud)\n",
        "#public = ngrok.connect(8088, proto=\"http\")   # forwards 8080 ‚Üí HTTPS URL\n",
        "from gs.trainers.basic import *\n",
        "\n",
        "train(model = model,\n",
        "      cameras = train_cams,\n",
        "      iterations = 10000,\n",
        "      )"
      ],
      "metadata": {
        "id": "gYiperlR0Gga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------- Imports --------------------------------------------------------------\n",
        "import os,tempfile, zipfile, requests, imageio, torch\n",
        "from pathlib import Path\n",
        "from plyfile import PlyElement\n",
        "\n",
        "from gs.core.GaussianModel import GaussianModel\n",
        "from gs.io.colmap import load\n",
        "from gs.helpers.loss import l1_loss\n",
        "\n"
      ],
      "metadata": {
        "id": "EFF3gube1fZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GaussianModel.from_point_cloud(pointcloud)\n",
        "#public = ngrok.connect(8088, proto=\"http\")   # forwards 8080 ‚Üí HTTPS URL\n",
        "from gs.trainers.basic import *\n",
        "\n",
        "train(model = model,\n",
        "      cameras = cameras,\n",
        "      iterations = 100000,\n",
        "      )"
      ],
      "metadata": {
        "id": "lBAn_Myf2FVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "id": "pbhnemgGhQmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, numpy as np\n",
        "from plyfile import PlyData, PlyElement\n",
        "from pathlib import Path\n",
        "from gs.helpers.math import inverse_sigmoid   # already used in your code\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "def add_plane_gaussians_and_save(model,\n",
        "                                 out_ply=\"with_plane_markers.ply\",\n",
        "                                 rect_side_fraction=0.3,\n",
        "                                 marker_scale=0.05,\n",
        "                                 marker_opacity=0.9):\n",
        "    \"\"\"\n",
        "    Append 6 red 'indicator' Gaussians (4 rectangle corners + 2 arrow points)\n",
        "    that visualise the global plane stored in model.plane_p / model.plane_n,\n",
        "    then save everything as one PLY file.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    rect_side_fraction : float   size of square marker vs. scene diagonal\n",
        "    marker_scale       : float   isotropic std-dev [world units]\n",
        "    marker_opacity     : float   [0‚Äì1] alpha of the red blobs\n",
        "    \"\"\"\n",
        "    device = model.positions.device\n",
        "    dtype  = model.positions.dtype\n",
        "    N      = len(model)\n",
        "\n",
        "    # 1. build 6 indicator positions ---------------------------------\n",
        "    p0   = model.plane_p.detach().cpu().numpy()\n",
        "    nhat = model.plane_n.detach().cpu().numpy()\n",
        "\n",
        "    # two orthonormal in-plane vectors\n",
        "    u = np.cross([1, 0, 0], nhat); u /= np.linalg.norm(u)\n",
        "    v = np.cross(nhat, u)\n",
        "    side = rect_side_fraction * np.linalg.norm(model.positions.detach().cpu().numpy().ptp(0))\n",
        "\n",
        "    rect = np.array([ p0 + side*(+u+v),\n",
        "                      p0 + side*(+u-v),\n",
        "                      p0 + side*(-u-v),\n",
        "                      p0 + side*(-u+v) ])          # (4,3)\n",
        "    arrow = np.vstack([p0, p0 + nhat*0.5*side])     # (2,3)\n",
        "    P_ind = np.vstack([rect, arrow])                # (6,3)\n",
        "\n",
        "    # 2. create Gaussian parameters for the indicators ---------------\n",
        "    M = P_ind.shape[0]\n",
        "    pos_t   = torch.tensor(P_ind, dtype=dtype, device=device)\n",
        "    rot_t   = torch.zeros((M,4), dtype=dtype, device=device); rot_t[:,0] = 1\n",
        "    sca_t   = torch.log(torch.full((M,3), marker_scale, dtype=dtype, device=device))\n",
        "    opa_t   = inverse_sigmoid(torch.full((M,1), marker_opacity, dtype=dtype, device=device))\n",
        "\n",
        "    # SH coefficients: DC term = bright red, others zero\n",
        "    D = (model.sh_degree + 1) ** 2\n",
        "    sh_t = torch.zeros((M, D, 3), dtype=dtype, device=device)\n",
        "    sh_t[:,0,0] = 1.0   # red channel DC\n",
        "\n",
        "    # 3. concatenate to the model ------------------------------------\n",
        "    model.positions            = nn.Parameter(torch.cat([model.positions, pos_t], 0))\n",
        "    model.rotations            = nn.Parameter(torch.cat([model.rotations, rot_t], 0))\n",
        "    model.scales               = nn.Parameter(torch.cat([model.scales,    sca_t], 0))\n",
        "    model.opacities            = nn.Parameter(torch.cat([model.opacities, opa_t], 0))\n",
        "    model.sh_coefficients_0    = nn.Parameter(torch.cat([model.sh_coefficients_0,\n",
        "                                                         sh_t[:,:1,:]], 0))\n",
        "    model.sh_coefficients_rest = nn.Parameter(torch.cat([model.sh_coefficients_rest,\n",
        "                                                         sh_t[:,1:,:]], 0))\n",
        "    # etas‚Äîkeep same size by duplicating last value\n",
        "    model.etas                 = nn.Parameter(torch.cat([model.etas,\n",
        "                                                         model.etas[-1:].repeat(M,1)], 0))\n",
        "\n",
        "    # 4. write a single PLY (reuse existing save_ply method) ----------\n",
        "    model.save_ply(out_ply)\n",
        "    print(f\"‚úì Augmented model + plane markers written to {Path(out_ply).resolve()}\")\n",
        "model.save_ply(\"./model.ply\")\n"
      ],
      "metadata": {
        "id": "4vGnQqVR2Q36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# autoreload\n",
        "%autoreload\n",
        "from gs.core.GaussianModel import GaussianModel\n",
        "\n",
        "model2 = GaussianModel.from_point_cloud(pointcloud=pointcloud)"
      ],
      "metadata": {
        "id": "LHhfNDSDFRtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# get from ply"
      ],
      "metadata": {
        "id": "_hN9GUowDesk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os,tempfile, zipfile, requests, imageio, torch\n",
        "from pathlib import Path\n",
        "from plyfile import PlyElement\n",
        "from gs.core.GaussianModel import GaussianModel\n",
        "\n",
        "model = GaussianModel.from_ply(\"./model_19000.ply\")"
      ],
      "metadata": {
        "id": "2FKVFNmrDeYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gs.io.colmap import load\n",
        "\n",
        "# ------- Load COLMAP data -----------------------------------------------------\n",
        "# Expects: BARN_DIR/sparse/0/{cameras.bin, images.bin, points3D.bin}, BARN_DIR/images/*\n",
        "cameras, pointcloud = load(str(\"red_truck_GS\"))\n",
        "print(f\"Loaded {len(cameras)} cameras and {len(pointcloud.points)} sparse points from red_truck_GS\")\n",
        "\n"
      ],
      "metadata": {
        "id": "LefVYCEREyPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gs.trainers.basic import *\n",
        "model = GaussianModel.from_point_cloud(pointcloud)\n",
        "project=\"gs-red-truck\"\n",
        "run = wandb.init(project=project, resume=\"allow\")\n",
        "\n",
        "train(model = model,\n",
        "      cameras = train_cams,\n",
        "      iterations = 50000,\n",
        "      val_cams = val_cams,\n",
        "      run = run\n",
        "      )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "je2OTR_FIhpX",
        "outputId": "9b1ba231-ddb0-456a-851a-b8291129fb8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">visionary-smoke-15</strong> at: <a href='https://wandb.ai/nadavoteam/gs-red-truck/runs/q575pwjj' target=\"_blank\">https://wandb.ai/nadavoteam/gs-red-truck/runs/q575pwjj</a><br> View project at: <a href='https://wandb.ai/nadavoteam/gs-red-truck' target=\"_blank\">https://wandb.ai/nadavoteam/gs-red-truck</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250531_212514-q575pwjj/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250531_212649-xwfuvbue</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nadavoteam/gs-red-truck/runs/xwfuvbue' target=\"_blank\">lemon-sponge-16</a></strong> to <a href='https://wandb.ai/nadavoteam/gs-red-truck' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/nadavoteam/gs-red-truck' target=\"_blank\">https://wandb.ai/nadavoteam/gs-red-truck</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/nadavoteam/gs-red-truck/runs/xwfuvbue' target=\"_blank\">https://wandb.ai/nadavoteam/gs-red-truck/runs/xwfuvbue</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ \u001b[1mviser\u001b[0m ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ\n",
              "‚îÇ             ‚ï∑                         ‚îÇ\n",
              "‚îÇ   HTTP      ‚îÇ http://localhost:8087   ‚îÇ\n",
              "‚îÇ   Websocket ‚îÇ ws://localhost:8087     ‚îÇ\n",
              "‚îÇ             ‚ïµ                         ‚îÇ\n",
              "‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ <span style=\"font-weight: bold\">viser</span> ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ\n",
              "‚îÇ             ‚ï∑                         ‚îÇ\n",
              "‚îÇ   HTTP      ‚îÇ http://localhost:8087   ‚îÇ\n",
              "‚îÇ   Websocket ‚îÇ ws://localhost:8087     ‚îÇ\n",
              "‚îÇ             ‚ïµ                         ‚îÇ\n",
              "‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.10523281991481781:   3%|‚ñé         | 1499/50000 [00:48<24:58, 32.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.11/dist-packages/lpips/weights/v0.1/vgg.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.1315668225288391:   3%|‚ñé         | 1503/50000 [00:54<5:25:19,  2.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ logged iter 1500 to W&B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.049127064645290375:   9%|‚ñâ         | 4500/50000 [02:48<31:33, 24.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.11/dist-packages/lpips/weights/v0.1/vgg.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.05019332841038704:   9%|‚ñâ         | 4503/50000 [02:55<8:57:33,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ logged iter 4500 to W&B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.01780031807720661:  15%|‚ñà‚ñç        | 7498/50000 [05:16<36:16, 19.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.11/dist-packages/lpips/weights/v0.1/vgg.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.0377473309636116:  15%|‚ñà‚ñå        | 7503/50000 [05:24<8:20:19,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ logged iter 7500 to W&B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.027910348027944565:  21%|‚ñà‚ñà        | 10498/50000 [07:52<32:44, 20.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.11/dist-packages/lpips/weights/v0.1/vgg.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.038820721209049225:  21%|‚ñà‚ñà        | 10503/50000 [07:59<6:47:13,  1.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ logged iter 10500 to W&B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.037837132811546326:  27%|‚ñà‚ñà‚ñã       | 13499/50000 [10:30<29:43, 20.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.11/dist-packages/lpips/weights/v0.1/vgg.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.03252372890710831:  27%|‚ñà‚ñà‚ñã       | 13502/50000 [10:38<7:49:20,  1.30it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ logged iter 13500 to W&B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.031078103929758072:  33%|‚ñà‚ñà‚ñà‚ñé      | 16499/50000 [13:15<30:06, 18.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.11/dist-packages/lpips/weights/v0.1/vgg.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.0326710119843483:  33%|‚ñà‚ñà‚ñà‚ñé      | 16503/50000 [13:23<7:43:28,  1.20it/s]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ logged iter 16500 to W&B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.03285335376858711:  39%|‚ñà‚ñà‚ñà‚ñâ      | 19499/50000 [16:06<27:33, 18.44it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.11/dist-packages/lpips/weights/v0.1/vgg.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.026330996304750443:  39%|‚ñà‚ñà‚ñà‚ñâ      | 19503/50000 [16:14<7:00:42,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ logged iter 19500 to W&B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.027854956686496735:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 22500/50000 [18:58<24:47, 18.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.11/dist-packages/lpips/weights/v0.1/vgg.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.024164851754903793:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 22502/50000 [19:06<8:49:02,  1.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ logged iter 22500 to W&B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.026018941774964333:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 25499/50000 [21:53<23:03, 17.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.11/dist-packages/lpips/weights/v0.1/vgg.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.03794754296541214:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 25503/50000 [22:01<5:38:10,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ logged iter 25500 to W&B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.02900482341647148:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 28499/50000 [24:50<19:58, 17.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.11/dist-packages/lpips/weights/v0.1/vgg.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.030547983944416046:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 28503/50000 [24:57<4:58:26,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ logged iter 28500 to W&B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.02271130494773388:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 31499/50000 [27:47<17:17, 17.83it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.11/dist-packages/lpips/weights/v0.1/vgg.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.022485801950097084:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 31503/50000 [27:54<4:18:10,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ logged iter 31500 to W&B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.03200254216790199:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 34499/50000 [30:45<14:34, 17.72it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.11/dist-packages/lpips/weights/v0.1/vgg.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.024233730509877205:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 34503/50000 [30:52<3:34:45,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ logged iter 34500 to W&B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.02659299224615097:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 37499/50000 [33:44<12:00, 17.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.11/dist-packages/lpips/weights/v0.1/vgg.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.02865581586956978:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 37503/50000 [33:52<2:53:23,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ logged iter 37500 to W&B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.013539259321987629:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 40500/50000 [36:46<09:02, 17.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.11/dist-packages/lpips/weights/v0.1/vgg.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.026422511786222458:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 40502/50000 [36:53<3:04:20,  1.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ logged iter 40500 to W&B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.02584027126431465:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 43499/50000 [39:50<06:22, 16.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.11/dist-packages/lpips/weights/v0.1/vgg.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.020411115139722824:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 43503/50000 [39:58<1:29:59,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ logged iter 43500 to W&B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.022424016147851944:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 46499/50000 [42:57<03:29, 16.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.11/dist-packages/lpips/weights/v0.1/vgg.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.029119109734892845:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 46503/50000 [43:05<49:12,  1.18it/s]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ logged iter 46500 to W&B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.03001699224114418:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 49499/50000 [46:04<00:29, 16.75it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.11/dist-packages/lpips/weights/v0.1/vgg.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.025992782786488533:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 49503/50000 [46:11<06:51,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ logged iter 49500 to W&B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.022683579474687576: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50000/50000 [46:41<00:00, 17.85it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "this is the train validation step"
      ],
      "metadata": {
        "id": "DBMooaA3MSIl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_ply(f\"./model_final.ply\")"
      ],
      "metadata": {
        "id": "d1d3spv6MhxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(\"./model_37500.ply\")    # or \"aquatic_baseline_gs.pth\""
      ],
      "metadata": {
        "id": "1lTqjCrdMkUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os,tempfile, zipfile, requests, imageio, torch\n",
        "from pathlib import Path\n",
        "from plyfile import PlyElement\n",
        "from gs.core.GaussianModel import GaussianModel\n",
        "\n",
        "model = GaussianModel.from_ply(\"./model_37500.ply\").to(\"cuda\")"
      ],
      "metadata": {
        "id": "MZmc_3gYItSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, lpips\n",
        "print(torch.cuda.is_available())          # ‚Üí True\n",
        "print(torch.version.cuda)                 # e.g. 12.1\n",
        "print(torch.cuda.get_device_name(0))      # e.g. Tesla T4 / A100"
      ],
      "metadata": {
        "id": "FP5E-v3VM7LI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#=============================================================\n",
        "#\n",
        "#             validations & saving\n",
        "#\n",
        "#=============================================================\n",
        "with torch.no_grad():\n",
        "  rendered = model.forward(val_cams[0])\n",
        "#model.save_ply(f\"./model_{i}.ply\")\n",
        "vis = (rendered.clamp(0, 1).permute(1, 2, 0).detach().cpu().numpy() * 255).astype('uint8')\n",
        "imageio.imwrite(f\"preview_{i:04d}.png\", vis)"
      ],
      "metadata": {
        "id": "5geXCaS5MAjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = GaussianModel.from_point_cloud(pointcloud=pointcloud).to(\"cuda\")"
      ],
      "metadata": {
        "id": "IPt85nqaJmlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "Wvx04gG9q_Mb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade wandb\n",
        "!wandb login  # paste your API key or run in a browser"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgjMTol-DOG7",
        "outputId": "83c29d78-6751-4288-adb0-fdd0e40fe487"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.11)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.2.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.29.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.4.26)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using legacy-service, which is deprecated. If this is unintentional, you can fix it by ensuring you do not call `wandb.require('legacy-service')` and do not set the WANDB_X_REQUIRE_LEGACY_SERVICE environment variable.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnadavo11\u001b[0m (\u001b[33mnadavoteam\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lpips, imageio, numpy as np\n",
        "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
        "from pathlib import Path, PurePath\n",
        "import torch, time, csv\n",
        "import csv, json, torch, lpips, imageio, numpy as np, matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
        "import csv, torch, lpips, imageio, wandb, numpy as np\n",
        "from pathlib import Path\n",
        "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
        "\n",
        "project=\"gs-red-truck\"\n",
        "run = wandb.init(project=project, resume=\"allow\")\n",
        "\n",
        "def eval_model_wandb(model, val_cams, iter_num, run = run,\n",
        "                     project=\"gs-red-truck\", device=\"cuda\"):\n",
        "\n",
        "    run = wandb.init(project=project, resume=\"allow\")\n",
        "\n",
        "    lpips_fn = lpips.LPIPS(net=\"vgg\").to(device).eval()\n",
        "    model = model.to(device).eval()\n",
        "\n",
        "    rows, psnr_all, ssim_all, lp_all = [], [], [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for cam in val_cams:\n",
        "            cam = cam.to(device)\n",
        "            pred = model.forward(cam, active_sh_degree=10).clamp(0, 1)\n",
        "            gt   = cam.image.float() / 255.0\n",
        "\n",
        "            psnr = peak_signal_noise_ratio(gt.cpu().numpy().transpose(1,2,0),\n",
        "                                           pred.cpu().numpy().transpose(1,2,0),\n",
        "                                           data_range=1.0)\n",
        "            ssim = structural_similarity(gt.cpu().numpy().transpose(1,2,0),\n",
        "                                         pred.cpu().numpy().transpose(1,2,0),\n",
        "                                         channel_axis=2, data_range=1.0)\n",
        "            lp   = lpips_fn(pred.unsqueeze(0), gt.unsqueeze(0)).item()\n",
        "\n",
        "            rows.append([cam.image_path, psnr, ssim, lp])\n",
        "            psnr_all.append(psnr); ssim_all.append(ssim); lp_all.append(lp)\n",
        "\n",
        "    # ---- Log aggregate numbers for this iteration -------------\n",
        "    run.log({\n",
        "        \"iter\":  iter_num,\n",
        "        \"val/psnr\":  np.mean(psnr_all),\n",
        "        \"val/ssim\":  np.mean(ssim_all),\n",
        "        \"val/lpips\": np.mean(lp_all),\n",
        "    }, step=iter_num)\n",
        "\n",
        "    # ---- Upload preview (first val view) ----------------------\n",
        "    first_cam = val_cams[0].to(device)\n",
        "    pred = model.forward(first_cam, active_sh_degree=10).clamp(0, 1).cpu().detach().numpy().transpose(1,2,0)\n",
        "    gt   = (first_cam.image.cpu().numpy().transpose(1,2,0) )\n",
        "    err  = np.abs(pred - gt) / np.maximum(np.abs(pred - gt).max(), 1e-8)\n",
        "\n",
        "    preview = np.concatenate([gt, pred, err], axis=1)\n",
        "    wandb_preview = wandb.Image((preview * 255).astype(np.uint8),\n",
        "                                caption=f\"iter {iter_num}\")\n",
        "    run.log({\"preview\": wandb_preview}, step=iter_num)\n",
        "\n",
        "    # ---- Save model ‚Üí artifact (versioned in W&B) -------------\n",
        "    ply_path = Path(f\"model_iter-{iter_num:04d}.ply\")\n",
        "    model.save_ply(\"./\"+str(ply_path))\n",
        "    art = wandb.Artifact(\"gaussian_cloud\", type=\"model\",\n",
        "                         description=\"Ply dump each val interval\")\n",
        "    art.add_file(str(ply_path))\n",
        "    run.log_artifact(art)\n",
        "\n",
        "    # ---- Optional: frame-level table (one row per view) -------\n",
        "    tbl = wandb.Table(columns=[\"frame\", \"psnr\", \"ssim\", \"lpips\"], data=rows)\n",
        "    run.log({f\"frame_metrics/iter_{iter_num}\": tbl}, step=iter_num)\n",
        "\n",
        "    print(f\"‚úÖ logged iter {iter_num} to W&B\")\n",
        "    run.finish()\n",
        "eval_model_wandb(model = model, val_cams = val_cams, iter_num = 42,project=\"gs-red-truck\"  )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 914
        },
        "id": "jlyMLi_jq9sc",
        "outputId": "15bd3c0c-c349-46d6-f4c7-e2d3d0f80dd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250531_211620-7teod9fs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nadavoteam/gs-red-truck/runs/7teod9fs' target=\"_blank\">daily-snowflake-10</a></strong> to <a href='https://wandb.ai/nadavoteam/gs-red-truck' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/nadavoteam/gs-red-truck' target=\"_blank\">https://wandb.ai/nadavoteam/gs-red-truck</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/nadavoteam/gs-red-truck/runs/7teod9fs' target=\"_blank\">https://wandb.ai/nadavoteam/gs-red-truck/runs/7teod9fs</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">daily-snowflake-10</strong> at: <a href='https://wandb.ai/nadavoteam/gs-red-truck/runs/7teod9fs' target=\"_blank\">https://wandb.ai/nadavoteam/gs-red-truck/runs/7teod9fs</a><br> View project at: <a href='https://wandb.ai/nadavoteam/gs-red-truck' target=\"_blank\">https://wandb.ai/nadavoteam/gs-red-truck</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250531_211620-7teod9fs/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250531_211621-f2yfpuhr</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nadavoteam/gs-red-truck/runs/f2yfpuhr' target=\"_blank\">azure-vortex-11</a></strong> to <a href='https://wandb.ai/nadavoteam/gs-red-truck' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/nadavoteam/gs-red-truck' target=\"_blank\">https://wandb.ai/nadavoteam/gs-red-truck</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/nadavoteam/gs-red-truck/runs/f2yfpuhr' target=\"_blank\">https://wandb.ai/nadavoteam/gs-red-truck/runs/f2yfpuhr</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from: /usr/local/lib/python3.11/dist-packages/lpips/weights/v0.1/vgg.pth\n",
            "‚úÖ logged iter 42 to W&B\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>iter</td><td>‚ñÅ</td></tr><tr><td>val/lpips</td><td>‚ñÅ</td></tr><tr><td>val/psnr</td><td>‚ñÅ</td></tr><tr><td>val/ssim</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>iter</td><td>42</td></tr><tr><td>val/lpips</td><td>0.53319</td></tr><tr><td>val/psnr</td><td>6.05453</td></tr><tr><td>val/ssim</td><td>0.01401</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">azure-vortex-11</strong> at: <a href='https://wandb.ai/nadavoteam/gs-red-truck/runs/f2yfpuhr' target=\"_blank\">https://wandb.ai/nadavoteam/gs-red-truck/runs/f2yfpuhr</a><br> View project at: <a href='https://wandb.ai/nadavoteam/gs-red-truck' target=\"_blank\">https://wandb.ai/nadavoteam/gs-red-truck</a><br>Synced 5 W&B file(s), 2 media file(s), 4 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250531_211621-f2yfpuhr/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TORCH_USE_CUDA_DSA = True"
      ],
      "metadata": {
        "id": "PYCGGZ_bgC6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch, random\n",
        "# from gs.core.GaussianModel import GaussianModel\n",
        "\n",
        "# root = \"red_truck_GS\"\n",
        "# cams_dict, _ = load(root)\n",
        "# cam = next(iter(cams_dict)).to(\"cuda\")\n",
        "\n",
        "# model = GaussianModel(sh_degree=0).to(\"cuda\")\n",
        "# # 1 tiny Gaussian so memory use is negligible\n",
        "# model.positions.data   = torch.zeros(1,3, device=\"cuda\")\n",
        "# model.scales.data      = torch.ones (1,3, device=\"cuda\")*0.01\n",
        "# model.opacities.data   = torch.ones (1,1, device=\"cuda\")*0.1\n",
        "# model.sh_coefficients_0.data[:] = 0.5\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "torch.cuda.synchronize()\n",
        "\n",
        "try:\n",
        "    with torch.no_grad():\n",
        "        frame = model.forward(cam, active_sh_degree=0)\n",
        "    print(\"‚úÖ forward ok, shape:\", frame.shape)\n",
        "except RuntimeError as e:\n",
        "    print(\"‚ùå still crashes, so the bug is kernel/driver\")\n",
        "    raise\n"
      ],
      "metadata": {
        "id": "s7ICudiGFEfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "64afkuZEF1CV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7bed86e6c3fe45888dc7b8a82815e812": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1bbfcac999744d2bbcdb9ae3bff4252a",
              "IPY_MODEL_2e4e999d8e6841a09a506f92a5d6a29d",
              "IPY_MODEL_2e6565837a2b407f9ddd08a19bd326a9"
            ],
            "layout": "IPY_MODEL_dbdb641761d245eeb3a485a6dbdd2fa1"
          }
        },
        "1bbfcac999744d2bbcdb9ae3bff4252a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7482aba2869745ebb42461c7ac331ac0",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e3380acf90a2413181a4a3491a34f055",
            "value": "Fetching‚Äá1334‚Äáfiles:‚Äá100%"
          }
        },
        "2e4e999d8e6841a09a506f92a5d6a29d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae0ef667a0d14f6ca759d38b16a50613",
            "max": 1334,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5e28997afeaf4e87bc16586577e11efd",
            "value": 1334
          }
        },
        "2e6565837a2b407f9ddd08a19bd326a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e830334d7514768bdcdd0f3ae1ed412",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c56ce44cfa304975a33c0a8b92c2a3d3",
            "value": "‚Äá1334/1334‚Äá[00:01&lt;00:00,‚Äá685.45it/s]"
          }
        },
        "dbdb641761d245eeb3a485a6dbdd2fa1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7482aba2869745ebb42461c7ac331ac0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3380acf90a2413181a4a3491a34f055": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae0ef667a0d14f6ca759d38b16a50613": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e28997afeaf4e87bc16586577e11efd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7e830334d7514768bdcdd0f3ae1ed412": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c56ce44cfa304975a33c0a8b92c2a3d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b3de518d7c041ac897b3fb8b3d31550": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f585bea34dc646a29bb34729ba537519",
              "IPY_MODEL_6c59ca379eb0438eb1353cff920ebb56",
              "IPY_MODEL_ca91fed513184892bc0e4f38ae497fde"
            ],
            "layout": "IPY_MODEL_9d34e8e50bec42e09175c70942a9e042"
          }
        },
        "f585bea34dc646a29bb34729ba537519": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0ba2780b38449ada7ecb92d151e4619",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_38d00262ef4a4461801f08558a4f18c4",
            "value": "val.txt:‚Äá100%"
          }
        },
        "6c59ca379eb0438eb1353cff920ebb56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0722f9426da3494f9f00ffda40b3278b",
            "max": 511,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e03f56ecab874ec0882e9cd4cb4cbcca",
            "value": 511
          }
        },
        "ca91fed513184892bc0e4f38ae497fde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b45418768dd546549681b9a1e0432e77",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_02818d284bef4c0ab083b71262548e17",
            "value": "‚Äá511/511‚Äá[00:00&lt;00:00,‚Äá25.0kB/s]"
          }
        },
        "9d34e8e50bec42e09175c70942a9e042": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0ba2780b38449ada7ecb92d151e4619": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38d00262ef4a4461801f08558a4f18c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0722f9426da3494f9f00ffda40b3278b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e03f56ecab874ec0882e9cd4cb4cbcca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b45418768dd546549681b9a1e0432e77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02818d284bef4c0ab083b71262548e17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "152dcf7d57dc4924a21d6e9eb59877ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_36222de2f2de4c738e8992dee986f4ff",
              "IPY_MODEL_70529781b06b49b98543acf2333db639",
              "IPY_MODEL_7e012eaf5d104b11a6fa8dbcc8996024"
            ],
            "layout": "IPY_MODEL_9891454ad27948459678e44fb53e0b13"
          }
        },
        "36222de2f2de4c738e8992dee986f4ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7ac9a657bf44549bd4dac732ce69a98",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_26a7104136474deeb803df9a8631424e",
            "value": "train.txt:‚Äá100%"
          }
        },
        "70529781b06b49b98543acf2333db639": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cef093ddb104cf89dfed1df99e03dd5",
            "max": 4687,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e8716887610d46e481f928149a7da2eb",
            "value": 4687
          }
        },
        "7e012eaf5d104b11a6fa8dbcc8996024": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8b1a1588378440d84411e6ca2245be0",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7ab5d174b3d046e2ae87d812f9aeab0b",
            "value": "‚Äá4.69k/4.69k‚Äá[00:00&lt;00:00,‚Äá532kB/s]"
          }
        },
        "9891454ad27948459678e44fb53e0b13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7ac9a657bf44549bd4dac732ce69a98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26a7104136474deeb803df9a8631424e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2cef093ddb104cf89dfed1df99e03dd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8716887610d46e481f928149a7da2eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a8b1a1588378440d84411e6ca2245be0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ab5d174b3d046e2ae87d812f9aeab0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}