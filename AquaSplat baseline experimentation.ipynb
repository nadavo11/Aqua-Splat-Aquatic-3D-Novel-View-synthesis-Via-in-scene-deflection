{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!git clone https://github.com/shiukaheng/minGS.git\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YaAlXeFwD8KR",
    "outputId": "4a8cb30f-2641-4a09-e50a-3d2ce4c7572b",
    "ExecuteTime": {
     "end_time": "2025-05-01T08:58:55.606067Z",
     "start_time": "2025-05-01T08:58:55.480140Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'minGS' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T08:58:58.910155Z",
     "start_time": "2025-05-01T08:58:58.896426Z"
    }
   },
   "cell_type": "code",
   "source": "print(\"hello world\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "import sys\n",
    "sys.path.append('/content/minGS')\n",
    "\n"
   ],
   "metadata": {
    "id": "Mfv-zf3ZFuHM"
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# make sure we have a compiler helper\n",
    "!pip install ninja  # speeds up CUDA builds\n",
    "\n",
    "# --- diff-gaussian-rasterization\n",
    "!pip install -e ./minGS/submodules/diff-gaussian-rasterization\n",
    "\n",
    "# --- simple-knn\n",
    "!pip install -e ./minGS/submodules/simple-knn"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p9AKBR67tO5z",
    "outputId": "a53f3acf-59ab-44d0-ba29-e3377ea02012"
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (1.11.1.4)\n",
      "Obtaining file:///content/minGS/submodules/diff-gaussian-rasterization\n",
      "  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Installing collected packages: diff_gaussian_rasterization\n",
      "  Attempting uninstall: diff_gaussian_rasterization\n",
      "    Found existing installation: diff_gaussian_rasterization 0.0.0\n",
      "    Uninstalling diff_gaussian_rasterization-0.0.0:\n",
      "      Successfully uninstalled diff_gaussian_rasterization-0.0.0\n",
      "  Running setup.py develop for diff_gaussian_rasterization\n",
      "Successfully installed diff_gaussian_rasterization-0.0.0\n",
      "Obtaining file:///content/minGS/submodules/simple-knn\n",
      "  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Installing collected packages: simple_knn\n",
      "  Attempting uninstall: simple_knn\n",
      "    Found existing installation: simple_knn 0.0.0\n",
      "    Uninstalling simple_knn-0.0.0:\n",
      "      Successfully uninstalled simple_knn-0.0.0\n",
      "  Running setup.py develop for simple_knn\n",
      "Successfully installed simple_knn-0.0.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install plyfile lpips viser requests imageio matplotlib --q"
   ],
   "metadata": {
    "id": "5bDJhGhgPcz8"
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Baseline script to train **minGS** on a small COLMAP dataset.\n",
    "- installs the minimal 3‑D Gaussian Splatting implementation\n",
    "- downloads a tiny demo dataset (bonsai) if `DATA_DIR` is empty\n",
    "- runs a very short training loop (2 k iters)\n",
    "- dumps preview renderings every 100 steps\n",
    "- saves the final model to `aquatic_baseline_gs.pth`\n",
    "\n",
    "You can use the same scaffolding later and simply swap the `GaussianModel.forward` call with your deflection‑aware version.\n"
   ],
   "metadata": {
    "id": "23RU14tUD8mr"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# data"
   ],
   "metadata": {
    "id": "fwX3XWotKVoH"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "id": "tRpy_iUToVN8"
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# aquatic_gs_baseline.py – baseline Gaussian Splatting demo (using Tanks&Temples 'Barn' COLMAP dataset)\n",
    "# Automatically install missing dependencies and run Gaussian Splatting demo for 'Barn'.\n",
    "\n",
    "# ------- Dependencies installation (run once at start) ------------------------\n",
    "import importlib\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# List of PyPI packages and minGS repo to ensure installed\n",
    "REQUIRED_PKGS = [\n",
    "    \"git+https://github.com/shiukaheng/minGS.git\",  # Gaussian Splatting core\n",
    "    \"plyfile\",                                       # COLMAP PLY support\n",
    "    \"lpips\",                                         # perceptual loss\n",
    "    \"viser\",                                         # visualization helper\n",
    "    \"requests\",                                      # HTTP\n",
    "    \"imageio\",                                       # image I/O\n",
    "    \"matplotlib\"                                     # plotting\n",
    "]\n",
    "\n",
    "for pkg in REQUIRED_PKGS:\n",
    "    name = pkg.split(\"#\")[0].strip()\n",
    "    try:\n",
    "        if name.startswith(\"git+\"):\n",
    "            importlib.import_module(\"gs\")\n",
    "        else:\n",
    "            importlib.import_module(name)\n",
    "    except ImportError:\n",
    "        print(f\"Installing {pkg}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg])\n",
    "\n",
    "# ------- Imports --------------------------------------------------------------\n",
    "import os,tempfile, zipfile, requests, imageio, torch\n",
    "from pathlib import Path\n",
    "from plyfile import PlyElement\n",
    "\n",
    "from gs.core.GaussianModel import GaussianModel\n",
    "from gs.io.colmap import load\n",
    "from gs.helpers.loss import l1_loss\n",
    "\n",
    "# ------- Prepare dataset ------------------------------------------------------\n",
    "# We'll download the authors' Tanks&Temples+DeepBlending COLMAP archive and extract only the 'tandt' scene\n",
    "ROOT = Path(\"./data\")\n",
    "DATA_DIR = Path(\"./data/tandt/train\")\n",
    "if not DATA_DIR.exists():\n",
    "    print(\"Dataset not found – downloading precomputed COLMAP for Tanks&Temples (650 MB)…\")\n",
    "    url = \"https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/datasets/input/tandt_db.zip\"\n",
    "    tmpfile = tempfile.NamedTemporaryFile(suffix=\".zip\", delete=False).name\n",
    "\n",
    "    resp = requests.get(url, stream=True)\n",
    "    resp.raise_for_status()\n",
    "    with open(tmpfile, \"wb\") as f:\n",
    "        for chunk in resp.iter_content(chunk_size=8192):\n",
    "            f.write(chunk)\n",
    "\n",
    "    with zipfile.ZipFile(tmpfile, 'r') as z:\n",
    "        members = [m for m in z.namelist()]\n",
    "        z.extractall(path=str(ROOT), members=members)\n",
    "    os.remove(tmpfile)\n",
    "\n",
    "# ------- Monkey-patch missing CUDA distance function --------------------------\n",
    "# import gs.core.GaussianModel as _gm\n",
    "# import torch as _torch\n",
    "# if not hasattr(_gm, 'distCUDA2'):\n",
    "#     def distCUDA2(a, b):\n",
    "#         return _torch.cdist(a, b)\n",
    "#     _gm.distCUDA2 = distCUDA2\n",
    "\n",
    "# ------- Load COLMAP data -----------------------------------------------------\n",
    "# Expects: BARN_DIR/sparse/0/{cameras.bin, images.bin, points3D.bin}, BARN_DIR/images/*\n",
    "cameras, pointcloud = load(str(DATA_DIR))\n",
    "print(f\"Loaded {len(cameras)} cameras and {len(pointcloud.points)} sparse points from Barn\")\n",
    "\n",
    "\n",
    "# ------- Build Gaussian Splatting model ---------------------------------------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = GaussianModel.from_point_cloud(pointcloud).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, eps=1e-15)\n",
    "\n",
    "# ------- Quick training loop --------------------------------------------------\n",
    "NUM_ITERS = 20000  # keep small for baseline; bump for quality\n",
    "LOG_EVERY = 1000\n",
    "\n",
    "for it in range(NUM_ITERS):\n",
    "    cam = cameras[it % len(cameras)].to(device)\n",
    "    rgb_pred = model(cam)\n",
    "    loss = l1_loss(rgb_pred, cam.image.to(device))\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "    if (it + 1) % LOG_EVERY == 0 or it == 0:\n",
    "        print(f\"iter {it+1:4d}/{NUM_ITERS} | L1 = {loss.item():.4f}\")\n",
    "        vis = (rgb_pred.clamp(0, 1).permute(1, 2, 0).detach().cpu().numpy() * 255).astype('uint8')\n",
    "        torch.save(model.state_dict(), \"aquatic_baseline_gs.pth\")\n",
    "\n",
    "\n",
    "        imageio.imwrite(f\"preview_{it+1:04d}.png\", vis)\n",
    "\n",
    "# ------- Save model -----------------------------------------------------------\n",
    "torch.save(model.state_dict(), \"aquatic_baseline_gs.pth\")\n",
    "print(\"Training finished – previews and checkpoint written.\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oltxL53IDigF",
    "outputId": "9ecc2cfe-da97-421d-92c8-5e5298a6fd1a"
   },
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loaded 301 cameras and 182686 sparse points from Barn\n",
      "iter    1/20000 | L1 = 0.2476\n",
      "iter 1000/20000 | L1 = 0.1143\n",
      "iter 2000/20000 | L1 = 0.0780\n",
      "iter 3000/20000 | L1 = 0.1275\n",
      "iter 4000/20000 | L1 = 0.0925\n",
      "iter 5000/20000 | L1 = 0.0820\n",
      "iter 6000/20000 | L1 = 0.0568\n",
      "iter 7000/20000 | L1 = 0.0795\n",
      "iter 8000/20000 | L1 = 0.0779\n",
      "iter 9000/20000 | L1 = 0.0418\n",
      "iter 10000/20000 | L1 = 0.0763\n",
      "iter 11000/20000 | L1 = 0.0681\n",
      "iter 12000/20000 | L1 = 0.0509\n",
      "iter 13000/20000 | L1 = 0.0722\n",
      "iter 14000/20000 | L1 = 0.0917\n",
      "iter 15000/20000 | L1 = 0.0697\n",
      "iter 16000/20000 | L1 = 0.0584\n",
      "iter 17000/20000 | L1 = 0.0814\n",
      "iter 18000/20000 | L1 = 0.1784\n",
      "iter 19000/20000 | L1 = 0.0431\n",
      "iter 20000/20000 | L1 = 0.0660\n",
      "Training finished – previews and checkpoint written.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#nice visuals"
   ],
   "metadata": {
    "id": "7MWUQgd6FtnI"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from gs.core.BaseCamera import BaseCamera\n",
    "\n",
    "# --- add a drop-in replacement ------------------------------------------------\n",
    "def _look_at(\n",
    "        eye: torch.Tensor,          # (3,)  camera position\n",
    "        center: torch.Tensor,       # (3,)  look-at point\n",
    "        up: torch.Tensor,           # (3,)  world-up\n",
    "        width: int, height: int,    # image size (px)\n",
    "        fx: float                   # focal length in px (assume square pixels)\n",
    "):\n",
    "    eye_np, center_np, up_np = map(lambda v: v.detach().cpu().numpy(), (eye, center, up))\n",
    "\n",
    "    # Build rotation (camera → world) with the usual OpenGL look-at convention\n",
    "    f = center_np - eye_np\n",
    "    f /= np.linalg.norm(f)\n",
    "    s = np.cross(f, up_np)\n",
    "    s /= np.linalg.norm(s)\n",
    "    u = np.cross(s, f)\n",
    "\n",
    "    # Camera‐to-world (R^T | eye); we need world-to-camera, so take the transpose.\n",
    "    R_c2w = np.stack([s, u, -f], axis=0)          # shape (3, 3)\n",
    "    R = R_c2w.T                                   # world → camera\n",
    "    t = -R @ eye_np                               # translation in camera frame\n",
    "\n",
    "    fov_x = 2 * np.arctan(width  / (2 * fx))\n",
    "    fov_y = 2 * np.arctan(height / (2 * fx))\n",
    "\n",
    "    return BaseCamera(\n",
    "        image_height=height,\n",
    "        image_width=width,\n",
    "        fov_x=float(fov_x),\n",
    "        fov_y=float(fov_y),\n",
    "        R=R.astype(np.float32),\n",
    "        t=t.astype(np.float32),\n",
    "    )\n",
    "\n",
    "# attach it so the rest of the code can stay identical\n",
    "BaseCamera.look_at = staticmethod(_look_at)\n",
    "# ------------------------------------------------------------------------------\n",
    "\n"
   ],
   "metadata": {
    "id": "lOmQAFlh6FTi"
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from gs.core.BaseCamera import BaseCamera\n",
    "\n",
    "def orbit_around_camera(\n",
    "        ref_cam: BaseCamera,\n",
    "        radius: float,\n",
    "        n_views: int = 120,\n",
    "        axis: str = \"yaw\",            # \"yaw\"  (spin left/right)\n",
    "                                        # \"pitch\" (tilt up/down)\n",
    "                                        # \"roll\"  (spin around optical axis)\n",
    "        up_hint: torch.Tensor | None = None,   # world-space up  (optional)\n",
    "        width: int = 800,\n",
    "        height: int = 800,\n",
    "        fx: float = 700,\n",
    ") -> list[BaseCamera]:\n",
    "\n",
    "    # -- extract the reference-camera transforms -----------------------------\n",
    "    R_wc = ref_cam.world_view_transform[:3, :3].T      # world←camera\n",
    "    t_wc = ref_cam.camera_center                       # camera position (world)\n",
    "\n",
    "    # local basis: x = right, y = up, z = -view\n",
    "    axis_vectors = {\n",
    "        \"yaw\":   torch.tensor([0, 1, 0]).to(device),   # rotate around local Y-up\n",
    "        \"pitch\": torch.tensor([1, 0, 0]).to(device),   # rotate around local X-right\n",
    "        \"roll\":  torch.tensor([0, 0, 1]).to(device),   # rotate around local Z-view\n",
    "    }\n",
    "    a_local = axis_vectors[axis].float()\n",
    "\n",
    "    # up vector for look_at; fall back to camera’s own +Y if none supplied\n",
    "    up_world = up_hint if up_hint is not None else R_wc @ torch.tensor([0, 1, 0],dtype=torch.float).to(device)\n",
    "\n",
    "    cams = []\n",
    "    for theta in torch.linspace(0.9*np.pi, 1.5*np.pi, n_views):\n",
    "        # rotation matrix in *camera* space, then send to world space\n",
    "        cos_t, sin_t = torch.cos(theta), torch.sin(theta)\n",
    "        if axis == \"yaw\":\n",
    "            R_delta = torch.tensor([[ cos_t, 0, sin_t],\n",
    "                                    [     0, 1,     0],\n",
    "                                    [-sin_t, 0, cos_t]]).to(device)\n",
    "        elif axis == \"pitch\":\n",
    "            R_delta = torch.tensor([[1,     0,      0],\n",
    "                                    [0, cos_t, -sin_t],\n",
    "                                    [0, sin_t,  cos_t]]).to(device)\n",
    "        else:  # roll\n",
    "            R_delta = torch.tensor([[cos_t, -sin_t, 0],\n",
    "                                    [sin_t,  cos_t, 0],\n",
    "                                    [    0,      0, 1]]).to(device)\n",
    "\n",
    "        # eye position: start at (radius,0,0) in ref-cam space, rotate, go world\n",
    "        eye_local  = torch.tensor([radius, 0, 0]).to(device)\n",
    "        eye_world  = (R_wc @ (R_delta @ eye_local)) + t_wc\n",
    "\n",
    "        # look-at point = pivot itself (camera centre)\n",
    "        cams.append(\n",
    "            BaseCamera.look_at(\n",
    "                eye_world, t_wc, up_world,\n",
    "                width=width, height=height, fx=fx\n",
    "            ).to(\"cuda\")\n",
    "        )\n",
    "\n",
    "    return cams\n"
   ],
   "metadata": {
    "id": "nas5mrzVK07B"
   },
   "execution_count": 118,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# get the video"
   ],
   "metadata": {
    "id": "3B9wx9EmOsuJ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# choose any dataset camera you like (e.g. index 0)\n",
    "ref_cam = cameras[16]\n",
    "\n",
    "# build an orbit that yaws 360° around that camera\n",
    "cams = orbit_around_camera(\n",
    "    ref_cam,\n",
    "    radius=2.0,      # metres in *camera* space\n",
    "    n_views=120,\n",
    "    axis=\"yaw\",       # try \"pitch\" or \"roll\" for other motions\n",
    "    width=800, height=800, fx=700\n",
    ")\n",
    "\n",
    "# render exactly as before\n",
    "frames = []\n",
    "for cam in cams:\n",
    "    with torch.no_grad():\n",
    "        img = model(cam).clamp(0,1).permute(1,2,0).cpu().numpy()\n",
    "    frames.append((img*255).astype(\"uint8\"))\n",
    "\n",
    "imageio.mimsave(\"pivot_turntable.mp4\", frames, fps=24)\n",
    "print(\"Saved pivot_turntable.mp4\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7bwUk89zK4Hw",
    "outputId": "87a4698c-2ba6-489a-c4c2-a2ee36cd8e76"
   },
   "execution_count": 119,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saved pivot_turntable.mp4\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "____________"
   ],
   "metadata": {
    "id": "2s-SbADRFz8a"
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
